{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Message</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "      <td>21</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "      <td>46</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>140</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "      <td>22</td>\n",
       "      <td>SG</td>\n",
       "      <td>2003/4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                            Message  \\\n",
       "0           0  10120                              Bugis oso near wat...   \n",
       "1           1  10121  Go until jurong point, crazy.. Available only ...   \n",
       "2           2  10122     I dunno until when... Lets go learn pilates...   \n",
       "3           3  10123  Den only weekdays got special price... Haiz......   \n",
       "4           4  10124                             Meet after lunch la...   \n",
       "\n",
       "  length country    Date  \n",
       "0     21      SG  2003/4  \n",
       "1    111      SG  2003/4  \n",
       "2     46      SG  2003/4  \n",
       "3    140      SG  2003/4  \n",
       "4     22      SG  2003/4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48598 entries, 0 to 48597\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  48598 non-null  int64 \n",
      " 1   id          48598 non-null  int64 \n",
      " 2   Message     48595 non-null  object\n",
      " 3   length      48598 non-null  object\n",
      " 4   country     48598 non-null  object\n",
      " 5   Date        48598 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"clean_nus_sms.csv\")\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Analyse what the most used words are in messages by different country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning on message variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Message'] = df['Message'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning on country variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "Singapore              22013\n",
      "SG                      9806\n",
      "India                   6901\n",
      "United States           3749\n",
      "USA                     1932\n",
      "Sri Lanka               1017\n",
      "Malaysia                 766\n",
      "Pakistan                 751\n",
      "unknown                  602\n",
      "Canada                   198\n",
      "Bangladesh               126\n",
      "China                    107\n",
      "india                    105\n",
      "INDIA                     79\n",
      "Philippines               67\n",
      "Indonesia                 48\n",
      "Nepal                     39\n",
      "srilanka                  30\n",
      "United Kingdom            30\n",
      "Hungary                   28\n",
      "Serbia                    22\n",
      "Kenya                     20\n",
      "Ghana                     18\n",
      "Italia                    10\n",
      "Turkey                    10\n",
      "Trinidad and Tobago       10\n",
      "Lebanon                   10\n",
      "Slovenia                  10\n",
      "Nigeria                   10\n",
      "New Zealand               10\n",
      "Macedonia                 10\n",
      "UK                        10\n",
      "Morocco                    9\n",
      "Romania                    9\n",
      "Australia                  9\n",
      "jamaica                    8\n",
      "BARBADOS                   8\n",
      "Spain                      5\n",
      "France                     5\n",
      "MY                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.country.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conver2 2 letter codes to full words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "Singapore                   31819\n",
      "India                        7085\n",
      "United States                3749\n",
      "United States of America     1932\n",
      "Sri Lanka                    1017\n",
      "Malaysia                      767\n",
      "Pakistan                      751\n",
      "unknown                       602\n",
      "Canada                        198\n",
      "Bangladesh                    126\n",
      "China                         107\n",
      "Philippines                    67\n",
      "Indonesia                      48\n",
      "Nepal                          39\n",
      "srilanka                       30\n",
      "United Kingdom                 30\n",
      "Hungary                        28\n",
      "Serbia                         22\n",
      "Kenya                          20\n",
      "Ghana                          18\n",
      "Turkey                         10\n",
      "Trinidad and Tobago            10\n",
      "Lebanon                        10\n",
      "Italia                         10\n",
      "Slovenia                       10\n",
      "Nigeria                        10\n",
      "New Zealand                    10\n",
      "Macedonia                      10\n",
      "UK                             10\n",
      "Morocco                         9\n",
      "Romania                         9\n",
      "Australia                       9\n",
      "Jamaica                         8\n",
      "Barbados                        8\n",
      "Spain                           5\n",
      "France                          5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from iso3166 import countries\n",
    "\n",
    "def convert_country_codes(code):\n",
    "    try:\n",
    "        return countries.get(code).name\n",
    "    except:\n",
    "        return code\n",
    "\n",
    "df['country'] = df['country'].apply(convert_country_codes)\n",
    "print(df.country.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert different capitalisations to be consistent. And merge USA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "SINGAPORE                   31819\n",
      "INDIA                        7085\n",
      "UNITED STATES                3749\n",
      "UNITED STATES OF AMERICA     1932\n",
      "SRI LANKA                    1017\n",
      "MALAYSIA                      767\n",
      "PAKISTAN                      751\n",
      "UNKNOWN                       602\n",
      "CANADA                        198\n",
      "BANGLADESH                    126\n",
      "CHINA                         107\n",
      "PHILIPPINES                    67\n",
      "INDONESIA                      48\n",
      "NEPAL                          39\n",
      "SRILANKA                       30\n",
      "UNITED KINGDOM                 30\n",
      "HUNGARY                        28\n",
      "SERBIA                         22\n",
      "KENYA                          20\n",
      "GHANA                          18\n",
      "TURKEY                         10\n",
      "TRINIDAD AND TOBAGO            10\n",
      "LEBANON                        10\n",
      "ITALIA                         10\n",
      "SLOVENIA                       10\n",
      "NIGERIA                        10\n",
      "NEW ZEALAND                    10\n",
      "MACEDONIA                      10\n",
      "UK                             10\n",
      "MOROCCO                         9\n",
      "ROMANIA                         9\n",
      "AUSTRALIA                       9\n",
      "JAMAICA                         8\n",
      "BARBADOS                        8\n",
      "SPAIN                           5\n",
      "FRANCE                          5\n",
      "Name: count, dtype: int64\n",
      "country\n",
      "SINGAPORE              31819\n",
      "INDIA                   7085\n",
      "UNITED STATES           5681\n",
      "SRI LANKA               1047\n",
      "MALAYSIA                 767\n",
      "PAKISTAN                 751\n",
      "UNKNOWN                  602\n",
      "CANADA                   198\n",
      "BANGLADESH               126\n",
      "CHINA                    107\n",
      "PHILIPPINES               67\n",
      "INDONESIA                 48\n",
      "UNITED KINGDOM            40\n",
      "NEPAL                     39\n",
      "HUNGARY                   28\n",
      "SERBIA                    22\n",
      "KENYA                     20\n",
      "GHANA                     18\n",
      "ITALIA                    10\n",
      "TRINIDAD AND TOBAGO       10\n",
      "LEBANON                   10\n",
      "TURKEY                    10\n",
      "NIGERIA                   10\n",
      "NEW ZEALAND               10\n",
      "SLOVENIA                  10\n",
      "MACEDONIA                 10\n",
      "MOROCCO                    9\n",
      "AUSTRALIA                  9\n",
      "ROMANIA                    9\n",
      "JAMAICA                    8\n",
      "BARBADOS                   8\n",
      "SPAIN                      5\n",
      "FRANCE                     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['country'] = df['country'].str.upper()\n",
    "print(df.country.value_counts())\n",
    "\n",
    "df['country'] = df['country'].replace('UNITED STATES OF AMERICA', 'UNITED STATES')\n",
    "df['country'] = df['country'].replace('UK', 'UNITED KINGDOM')\n",
    "df['country'] = df['country'].replace('SRILANKA', 'SRI LANKA')\n",
    "print(df.country.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing file needed to make this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "normalizer = WordNetLemmatizer()\n",
    "\n",
    "def get_part_of_speech(word):\n",
    "  probable_part_of_speech = wordnet.synsets(word)\n",
    "  pos_counts = Counter()\n",
    "  pos_counts[\"n\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"n\"]  )\n",
    "  pos_counts[\"v\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"v\"]  )\n",
    "  pos_counts[\"a\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"a\"]  )\n",
    "  pos_counts[\"r\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"r\"]  )\n",
    "  most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "  return most_likely_part_of_speech\n",
    "\n",
    "def preprocess_text(text):\n",
    "  cleaned = re.sub(r'\\W+', ' ', text).lower()\n",
    "  tokenized = word_tokenize(cleaned)\n",
    "  normalized = \" \".join([normalizer.lemmatize(token, get_part_of_speech(token)) for token in tokenized])\n",
    "  return normalized\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess documents\n",
    "df_country = df.groupby('country')['Message'].apply(' '.join).reset_index()\n",
    "\n",
    "processed_messages = {}\n",
    "for country in df_country['country']:\n",
    "    processed_messages[country] = preprocess_text(df_country[df_country['country'] == country]['Message'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tf-idf scores for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tfidf_scores = vectorizer.fit_transform(list(processed_messages.values()))\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_scores.toarray(), columns = feature_names, index=processed_messages.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse top most used words in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINGAPORE</th>\n",
       "      <th>UNITED STATES</th>\n",
       "      <th>INDIA</th>\n",
       "      <th>SRI LANKA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haha</td>\n",
       "      <td>you</td>\n",
       "      <td>be</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>be</td>\n",
       "      <td>to</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be</td>\n",
       "      <td>to</td>\n",
       "      <td>you</td>\n",
       "      <td>bles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>the</td>\n",
       "      <td>in</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>and</td>\n",
       "      <td>me</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>andreu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lol</td>\n",
       "      <td>get</td>\n",
       "      <td>the</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>can</td>\n",
       "      <td>that</td>\n",
       "      <td>for</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>so</td>\n",
       "      <td>do</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>get</td>\n",
       "      <td>can</td>\n",
       "      <td>ur</td>\n",
       "      <td>bless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>it</td>\n",
       "      <td>for</td>\n",
       "      <td>of</td>\n",
       "      <td>lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>at</td>\n",
       "      <td>have</td>\n",
       "      <td>come</td>\n",
       "      <td>anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>then</td>\n",
       "      <td>in</td>\n",
       "      <td>will</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hahaha</td>\n",
       "      <td>so</td>\n",
       "      <td>he</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my</td>\n",
       "      <td>me</td>\n",
       "      <td>no</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>me</td>\n",
       "      <td>just</td>\n",
       "      <td>da</td>\n",
       "      <td>andrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>for</td>\n",
       "      <td>we</td>\n",
       "      <td>do</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>okay</td>\n",
       "      <td>know</td>\n",
       "      <td>my</td>\n",
       "      <td>god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>le</td>\n",
       "      <td>my</td>\n",
       "      <td>have</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lor</td>\n",
       "      <td>your</td>\n",
       "      <td>your</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SINGAPORE UNITED STATES INDIA SRI LANKA\n",
       "0       haha           you    be       the\n",
       "1         to            be    to        be\n",
       "2         be            to   you      bles\n",
       "3         go           the    in       and\n",
       "4        the           and    me       you\n",
       "5        you            it    it    andreu\n",
       "6        lol           get   the        to\n",
       "7        can          that   for       may\n",
       "8         so            do   and        in\n",
       "9        get           can    ur     bless\n",
       "10        it           for    of      lord\n",
       "11        at          have  come      anna\n",
       "12      then            in  will      have\n",
       "13    hahaha            so    he        at\n",
       "14        my            me    no        of\n",
       "15        me          just    da    andrew\n",
       "16       for            we    do        hi\n",
       "17      okay          know    my       god\n",
       "18        le            my  have        me\n",
       "19       lor          your  your        it"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "country_list = ['SINGAPORE', 'UNITED STATES', 'INDIA', 'SRI LANKA']\n",
    "\n",
    "top_words_df = pd.DataFrame()\n",
    "for country in country_list:\n",
    "    total_words = tfidf_df.loc[country].sum()\n",
    "    country_word_df = tfidf_df.loc[country].div(total_words).sort_values(ascending=False).head(20)\n",
    "    top_words_df[country] = country_word_df.index\n",
    "display(top_words_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse most unique words in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINGAPORE</th>\n",
       "      <th>UNITED STATES</th>\n",
       "      <th>INDIA</th>\n",
       "      <th>SRI LANKA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lixian</td>\n",
       "      <td>wahala</td>\n",
       "      <td>ff</td>\n",
       "      <td>inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mocie</td>\n",
       "      <td>gucci</td>\n",
       "      <td>tuan</td>\n",
       "      <td>nalvalthukkal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moduleplanning</td>\n",
       "      <td>ross</td>\n",
       "      <td>jas</td>\n",
       "      <td>kurose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modify</td>\n",
       "      <td>rossknowing</td>\n",
       "      <td>jataya</td>\n",
       "      <td>kuruwita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modfass</td>\n",
       "      <td>gurren</td>\n",
       "      <td>ttoo</td>\n",
       "      <td>commin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>modern</td>\n",
       "      <td>gumby</td>\n",
       "      <td>jatey</td>\n",
       "      <td>immeasurably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>moderation</td>\n",
       "      <td>roughtimeline</td>\n",
       "      <td>jatin</td>\n",
       "      <td>garusinghe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>modem</td>\n",
       "      <td>guitarin</td>\n",
       "      <td>jaun</td>\n",
       "      <td>kyrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>moboy</td>\n",
       "      <td>guessthey</td>\n",
       "      <td>jawab</td>\n",
       "      <td>dsdys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mng</td>\n",
       "      <td>guessin</td>\n",
       "      <td>jaya</td>\n",
       "      <td>namal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobo</td>\n",
       "      <td>vivocity</td>\n",
       "      <td>jayachandran</td>\n",
       "      <td>comisn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mobilization</td>\n",
       "      <td>rrrrrryyyyyyaaaaaaannnnnnnn</td>\n",
       "      <td>jayawardhana</td>\n",
       "      <td>nalvaalthukal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mny</td>\n",
       "      <td>guyssaid</td>\n",
       "      <td>tukdo</td>\n",
       "      <td>lasanthi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mnot</td>\n",
       "      <td>rryyyaannn</td>\n",
       "      <td>jbe</td>\n",
       "      <td>nalaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mnodiscussion</td>\n",
       "      <td>gtf</td>\n",
       "      <td>jbo</td>\n",
       "      <td>returnd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mno</td>\n",
       "      <td>gshfhsg</td>\n",
       "      <td>tuesdy</td>\n",
       "      <td>imayams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>moh</td>\n",
       "      <td>gsf</td>\n",
       "      <td>tufan</td>\n",
       "      <td>patiently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mohamad</td>\n",
       "      <td>rue</td>\n",
       "      <td>jchlo</td>\n",
       "      <td>dtn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mohawk</td>\n",
       "      <td>grumpy</td>\n",
       "      <td>tughe</td>\n",
       "      <td>dtv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mohmd</td>\n",
       "      <td>vitamin</td>\n",
       "      <td>changa</td>\n",
       "      <td>amaithiyum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SINGAPORE                UNITED STATES         INDIA      SRI LANKA\n",
       "0           lixian                       wahala            ff            inc\n",
       "1            mocie                        gucci          tuan  nalvalthukkal\n",
       "2   moduleplanning                         ross           jas         kurose\n",
       "3           modify                  rossknowing        jataya       kuruwita\n",
       "4          modfass                       gurren          ttoo         commin\n",
       "5           modern                        gumby         jatey   immeasurably\n",
       "6       moderation                roughtimeline         jatin     garusinghe\n",
       "7            modem                     guitarin          jaun          kyrie\n",
       "8            moboy                    guessthey         jawab          dsdys\n",
       "9              mng                      guessin          jaya          namal\n",
       "10            mobo                     vivocity  jayachandran         comisn\n",
       "11    mobilization  rrrrrryyyyyyaaaaaaannnnnnnn  jayawardhana  nalvaalthukal\n",
       "12             mny                     guyssaid         tukdo       lasanthi\n",
       "13            mnot                   rryyyaannn           jbe         nalaka\n",
       "14   mnodiscussion                          gtf           jbo        returnd\n",
       "15             mno                      gshfhsg        tuesdy        imayams\n",
       "16             moh                          gsf         tufan      patiently\n",
       "17         mohamad                          rue         jchlo            dtn\n",
       "18          mohawk                       grumpy         tughe            dtv\n",
       "19           mohmd                      vitamin        changa     amaithiyum"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_words_df = pd.DataFrame()\n",
    "for country in country_list:\n",
    "    unique_word_df = tfidf_df.loc[country].div(tfidf_df.sum()).sort_values(ascending=False).head(20)\n",
    "    unique_words_df[country] = unique_word_df.index\n",
    "display(unique_words_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
