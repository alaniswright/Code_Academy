{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NATURAL LANGUAGE PARSING WITH REGULAR EXPRESSIONS\n",
    "\n",
    "By using Python’s regular expression modulere and the Natural Language Toolkit, known as NLTK, you can find keywords of interest, discover where and how often they are used, and discern the parts-of-speech patterns in which they appear to understand the sometimes hidden meaning in a piece of writing\n",
    "\n",
    "## Compiling and Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 7), match='Dorothy'>\n",
      "Dorothy\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# characters are defined\n",
    "character_1 = \"Dorothy\"\n",
    "character_2 = \"Henry\"\n",
    "\n",
    "# .compile() a regular expression object named regular_expression that will match any 7 character string of word characters.\n",
    "regular_expression = re.compile(\"[A-Za-z]{7}\")\n",
    "\n",
    "# check for a match to character_1 here\n",
    "result_1 = regular_expression.match(character_1)\n",
    "print(result_1)\n",
    "\n",
    "# store and print the matched text here\n",
    "match_1 = result_1.group(0)\n",
    "print(match_1)\n",
    "\n",
    "# compile a regular expression to match a 7 character string of word characters and check for a match to character_2 here\n",
    "result_2 = regular_expression.match(character_2)\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching and Finding\n",
    "\n",
    "Unlike .match() which will only find matches at the start of a string, .search() will look left to right through an entire piece of text and return a match object for the first match to the regular expression given. If no match is found, .search() will return None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Munchkin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_16104\\3021450304.py:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  result = re.search(\"\\w{8}\",\"Are you a Munchkin?\")\n"
     ]
    }
   ],
   "source": [
    "result = re.search(\"\\w{8}\",\"Are you a Munchkin?\")\n",
    "print(result.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a regular expression as its first argument and a string as its second argument, .findall() will return a list of all non-overlapping matches of the regular expression in the string. Consider the below piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Everythi', 'Munchkin', 'favorite', 'friendly', 'Munchkin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_16104\\2987421541.py:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  list_of_matches = re.findall(\"\\w{8}\",text)\n"
     ]
    }
   ],
   "source": [
    "text = \"Everything is green here, while in the country of the Munchkins blue was the favorite color. But the people do not seem to be as friendly as the Munchkins, and I'm afraid we shall be unable to find a place to pass the night.\"\n",
    "\n",
    "list_of_matches = re.findall(\"\\w{8}\",text)\n",
    "\n",
    "print(list_of_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech tagging\n",
    "\n",
    "you can often find more meaning by analyzing text on a word-by-word basis, focusing on the part of speech of each word in a sentence\n",
    "\n",
    "- Noun: the name of a person (Ramona,class), place, thing (textbook), or idea (NLP)\n",
    "- Pronoun: a word used in place of a noun (her,she)\n",
    "- Determiner: a word that introduces, or “determines”, a noun (the)\n",
    "- Verb: expresses action (studying) or being (are,has)\n",
    "- Adjective: modifies or describes a noun or pronoun (new)\n",
    "- Adverb: modifies or describes a verb, an adjective, or another adverb (happily)\n",
    "- Preposition: a word placed before a noun or pronoun to form a phrase modifying another word in the sentence (on)\n",
    "- Conjunction: a word that joins words, phrases, or clauses (and)\n",
    "- Interjection: a word used to express emotion (Wow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('do', 'VB'), ('you', 'PRP'), ('suppose', 'VB'), ('oz', 'NNS'), ('could', 'MD'), ('give', 'VB'), ('me', 'PRP'), ('a', 'DT'), ('heart', 'NN'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "word_sentence = ['do', 'you', 'suppose', 'oz', 'could', 'give', 'me', 'a', 'heart', '?']\n",
    "\n",
    "part_of_speech_tagged_sentence = pos_tag(word_sentence)\n",
    "\n",
    "print(part_of_speech_tagged_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "With chunking in nltk, you can define a pattern of parts-of-speech tags using a modified notation of regular expressions. You can then find non-overlapping matches, or chunks of words, in the part-of-speech tagged sentences of a text.\n",
    "\n",
    "The regular expression you build to find chunks is called chunk grammar. A piece of chunk grammar can be written as follows:\n",
    "\n",
    "chunk_grammar = \"AN: {\\<JJ>\\<NN>}\"\n",
    "\n",
    "- AN is a user-defined name for the kind of chunk you are searching for. You can use whatever name makes sense given your chunk grammar. In this case AN stands for adjective-noun\n",
    "- A pair of curly braces {} surround the actual chunk grammar\n",
    "- \\<JJ> operates similarly to a regex character class, matching any adjective\n",
    "- \\<NN> matches any noun, singular or plural\n",
    "\n",
    "The chunk grammar above will thus match any adjective that is followed by a noun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S where/WRB is/VBZ the/DT (AN emerald/JJ city/NN) ?/.)\n",
      "                   S                              \n",
      "     ______________|____________________           \n",
      "    |       |      |     |              AN        \n",
      "    |       |      |     |       _______|_____     \n",
      "where/WRB is/VBZ the/DT ?/. emerald/JJ     city/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpParser, Tree\n",
    "\n",
    "# Match any adjective followed by a noun\n",
    "chunk_grammar = \"AN: {<JJ><NN>}\"\n",
    "\n",
    "# Create a nltk RegexpParser object and give it a piece of chunk grammar as an argument\n",
    "chunk_parser = RegexpParser(chunk_grammar)\n",
    "\n",
    "\n",
    "pos_tagged_sentence = [('where', 'WRB'), ('is', 'VBZ'), ('the', 'DT'), ('emerald', 'JJ'), ('city', 'NN'), ('?', '.')]\n",
    "\n",
    "# use the RegexpParser object’s .parse() method, \n",
    "# which takes a list of part-of-speech tagged words as an argument, \n",
    "# and identifies where such chunks occur in the sentence!\n",
    "chunked = chunk_parser.parse(pos_tagged_sentence)\n",
    "\n",
    "print(chunked)\n",
    "\n",
    "Tree.fromstring(str(chunked)).pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking noun phrases\n",
    "\n",
    "Noun phrase chunking is particularly useful for deterining meaning and bias in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  so/RB\n",
      "  grateful/JJ\n",
      "  to/TO\n",
      "  you/PRP\n",
      "  for/IN\n",
      "  having/VBG\n",
      "  killed/VBN\n",
      "  the/DT\n",
      "  (AN wicked/JJ witch/NN)\n",
      "  of/IN\n",
      "  the/DT\n",
      "  east/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  for/IN\n",
      "  setting/VBG\n",
      "  our/PRP$\n",
      "  people/NNS\n",
      "  free/VBP\n",
      "  from/IN\n",
      "  bondage/NN\n",
      "  ./.)\n",
      "                                                                                                   S                                                                                                            \n",
      "   ________________________________________________________________________________________________|_________________________________________________________________________________________________            \n",
      "  |       |      |        |        |      |      |        |          |        |      |     |       |     |    |      |         |         |         |         |        |        |       |             AN         \n",
      "  |       |      |        |        |      |      |        |          |        |      |     |       |     |    |      |         |         |         |         |        |        |       |       ______|_____      \n",
      "we/PRP are/VBP so/RB grateful/JJ to/TO you/PRP for/IN having/VBG killed/VBN the/DT of/IN the/DT east/NN ,/, and/CC for/IN setting/VBG our/PRP$ people/NNS free/VBP from/IN bondage/NN ./. wicked/JJ     witch/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_tagged_sentence = [('we', 'PRP'), ('are', 'VBP'), ('so', 'RB'), ('grateful', 'JJ'), ('to', 'TO'), ('you', 'PRP'), ('for', 'IN'), ('having', 'VBG'), ('killed', 'VBN'), ('the', 'DT'), ('wicked', 'JJ'), ('witch', 'NN'), ('of', 'IN'), ('the', 'DT'), ('east', 'NN'), (',', ','), ('and', 'CC'), ('for', 'IN'), ('setting', 'VBG'), ('our', 'PRP$'), ('people', 'NNS'), ('free', 'VBP'), ('from', 'IN'), ('bondage', 'NN'), ('.', '.')]\n",
    "\n",
    "chunk_grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "chunked = chunk_parser.parse(pos_tagged_sentence)\n",
    "print(chunked)\n",
    "Tree.fromstring(str(chunked)).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NP is the user-defined name of the chunk you are searching for. In this case NP stands for noun phrase\n",
    "- \\<DT> matches any determiner\n",
    "- ? is an optional quantifier, matching either 0 or 1 determiners\n",
    "- \\<JJ> matches any adjective\n",
    "- \\* is the Kleene star quantifier, matching 0 or more occurrences of an adjective\n",
    "- \\<NN> matches any noun, singular or plural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Verb Phrases\n",
    "\n",
    "Another popular type of chunking is VP-chunking, or verb phrase chunking. A verb phrase is a phrase that contains a verb and its complements, objects, or modifiers.\n",
    "\n",
    "Verb phrases can take a variety of structures, and here you will consider two. The first structure begins with a verb VB of any tense, followed by a noun phrase, and ends with an optional adverb RB of any form. The second structure switches the order of the verb and the noun phrase, but also ends with an optional adverb.\n",
    "\n",
    "- VP is the user-defined name of the chunk you are searching for. In this case VP stands for verb phrase\n",
    "- \\<VB.*> matches any verb using the . as a wildcard and the * quantifier to match 0 or more occurrences of any character. This ensures matching verbs of any tense (ex. VB for present tense, VBD for past tense, or VBN for past participle)\n",
    "- \\<DT>?\\<JJ>*\\<NN> matches any noun phrase\n",
    "- \\<RB.?> matches any adverb using the . as a wildcard and the optional quantifier to match 0 or 1 occurrence of any character. This ensures matching any form of adverb (regular RB, comparative RBR, or superlative RBS)\n",
    "- ? is an optional quantifier, matching either 0 or 1 adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb1 = \"VP: {<VB.*><DT>?<JJ>*<NN><RB.?>?}\"\n",
    "\n",
    "verb2 = \"VP: {<DT>?<JJ>*<NN><VB.*><RB.?>?}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk filtering\n",
    "\n",
    "Chunk filtering lets you define what parts of speech you do not want in a chunk and remove them.\n",
    "\n",
    "A popular method for performing chunk filtering is to chunk an entire sentence together and then indicate which parts of speech are to be filtered out. If the filtered parts of speech are in the middle of a chunk, it will split the chunk into two separate chunks! The chunk grammar you can use to perform chunk filtering is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_grammar = \"\"\"NP: {<.*>+}\n",
    "                       }<VB.?|IN>+{\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NP is the user-defined name of the chunk you are searching for. In this case NP stands for noun phrase\n",
    "- The brackets {} indicate what parts of speech you are chunking. <.*>+ matches every part of speech in the sentence\n",
    "- The inverted brackets }{ indicate which parts of speech you want to filter from the chunk. <VB.?|IN>+ will filter out any verbs or prepositions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
